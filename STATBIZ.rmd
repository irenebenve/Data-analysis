# Data-analysis
### LOW DIMENSIONAL MODEL ANALYSIS
This analysis aims to investigate the impact of "International Plan" and "Total Day Minutes" on customer churn using logistic regression models. The models are trained on different datasets (normal, undersampled, and oversampled) to address class imbalance and compare the results.

### Model trained on the original data (unbalanced) 
Effect of Total Day Minutes and International Plan across all models, having an international plan significantly impacts the probability of churn. The interaction term indicates that the effect of total day minutes on churn probability varies based on whether the customer has an international plan.
The model trained on the original data (unbalanced) may suffer from class imbalance, potentially leading to biased predictions towards the majority class. 
PLOT
The diagram shows the probability of Churn by Total Day Minutes and International Plan (Unbalanced). On the X-axis are represented the total day minutes, while on the Y-axis the probability of churn. The red line, which represent the absence of international plans, shoews a steep increase in the probability of churn as Total Day Minutes increses. On the other hand, is clear that the blue line (adherence to international plans) increases in a more gradual way.


### The undersampled model
The undersampled model aims to provide a balanced view but might discard important information due to reduced data size.
PLOT
This plot provide a graphical representation for Probability of Churn by Total Day Minutes and International Plan (Balanced). Keeping in mind that the values of the axis are the same as in the previous diagram, we can focus on the different tendency of the factores analyzed: in this case, the red line again shows a steep increase in the probability of churn as Total Day Minutes increase, but starting from a higher base compared to the unbalanced case; The blue line (Yes International Plan) shows a less steep but still increasing trend, starting from a higher base as well.


### The oversampled model
The oversampled model attempts to balance the classes by increasing the minority instances, which can improve the model's ability to predict churn for the minority class but may also introduce overfitting.
PLOT
The Probability of Churn by Customer Service Calls (Balanced training set) is what is representented in the previous diagram, which shows the relation between the Customer Service Calls (on the X-axis) and the Probability of Churn (on the Y-axis). Only a single line is represented due to the lack of separation by International Plan. The probability of churn increases steadily as the number of customer service calls increases.


The predicted probabilities from the plots reveal the relationship between total day minutes and churn probability, moderated by the international plan. Customers with an international plan show a different churn probability pattern compared to those without it.

By comparing the models, we can see the trade-offs between different sampling strategies and their impact on the predictive performance. The visualizations help communicate these effects clearly, aiding in the understanding and interpretation of the logistic regression results. We can thrive a conlcusion from the vizualization of the previous relationships: the probability of churn in balanced datasets (second and third diagrams) starts at a higher base compared to the unbalanced dataset (first diagram).

This analysis highlights the importance of balancing datasets when building predictive models, especially in the presence of class imbalance. The interaction between total day minutes and the international plan provides valuable insights into customer churn behavior. Future steps could involve testing additional variables, using more advanced balancing techniques, and evaluating model performance using metrics like ROC-AUC and confusion matrices.

---

### LOGISTIC REGRESSION MODEL WITH CUSTOMER SERVICE CALLS 
Goal of the Analysis: This analysis aims to evaluate the impact of "Customer Service Calls" on customer churn using logistic regression models. The models are trained on different datasets (normal, undersampled, and oversampled) to address class imbalance and compare the results.

The number of customer service calls significantly impacts the probability of churn. As the number of customer service calls increases, the likelihood of churn also increases across all models.
The model trained on the original data (unbalanced) may be biased towards the majority class, potentially leading to underestimation of churn probability for the minority class.


The undersampled model addresses class imbalance by reducing the majority class instances, providing a more balanced view but possibly discarding some important information.
PLOT


The oversampled model balances the classes by increasing the minority instances, which can improve the model's ability to predict churn for the minority class but may also introduce overfitting.
PLOT


The predicted probabilities from the plots reveal a clear relationship between the number of customer service calls and churn probability. More customer service calls correspond to higher churn probabilities.


This analysis highlights the importance of balancing datasets when building predictive models, especially in the presence of class imbalance. The number of customer service calls is a strong predictor of customer churn. Future steps could involve testing additional variables, using more advanced balancing techniques, and evaluating model performance using metrics like ROC-AUC and confusion matrices.
By comparing the models, we can see the trade-offs between different sampling strategies and their impact on the predictive performance. The visualizations help communicate these effects clearly, aiding in the understanding and interpretation of the logistic regression results.






### CLASSIFICATION TREE
Goal of the Analysis: This analysis aims to evaluate the impact of "Total Day Minutes," "International Plan," and "Customer Service Calls" on customer churn using classification tree models. The models are trained on different datasets (normal, undersampled, and oversampled) to address class imbalance and compare the results. 

### Classification Tree with Normal Data
- The aim is to build a classification tree using the normal training dataset to predict customer churn based on "Total Day Minutes," "International Plan," and "Customer Service Calls." The tree structure is visualized to show decision rules, and a complexity parameter table is printed to assess model pruning. Variable importance is calculated to identify key predictors, and a confusion matrix is generated to evaluate model performance.
   ```r
   predictions_tree = predict(simple_tree, train_data, type = "class")
   confusion_matrix_tree = table(predictions_tree, train_data$Churn)
   print(confusion_matrix_tree)
   ```
PLOT
The tree regarding the classification with normal data reflects the original data distribution without balancing techniques.
The root node splits at `Total.day.minutes < 265`. Furthermore, ll trees use `Customer.service.calls < 4` for further splits, indicating the importance of customer service interactions.
Exhibits the lowest initial churn probability (0.15 at root) and splits with more specific conditions regarding total day minutes.


#### Classification Tree with Undersampled Data
The objective is to build a classification tree using undersampled data, which balances the classes by reducing the number of non-churn observations. The output is similar to the normal data model, the tree structure is visualized, complexity parameter table printed, variable importance calculated, and confusion matrix generated for model evaluation using the undersampled dataset.
**Plotting the Tree:**
   ```r
   rpart.plot(simple_tree_undersample, main = "Classification Tree - Undersample Data")
   ```
 **Confusion Matrix:**
   ```r
   predictions_tree_undersample = predict(simple_tree_undersample, train_data_undersample, type = "class")
   confusion_matrix_tree_undersample = table(predictions_tree_undersample, train_data_undersample$Churn)
   print(confusion_matrix_tree_undersample)
   ```
As we can see, the root node splits at `Total.day.minutes < 223`. In the under sample data, the trees use `Customer.service.calls < 4` as much as `International.plan` for further splits, indicating the importance of customer service interactions. It is used to handle imbalanced data by reducing majority class samples, and it finally results into a similar trend but with slightly different thresholds and probabilities.


#### Classification Tree with Oversampled Data
The goal is to build a classification tree using oversampled data, which balances the classes by increasing the number of churn observations. The tree structure is visualized for the oversampled dataset, complexity parameter table printed, variable importance calculated, and confusion matrix generated to evaluate model performance.
 **Complexity Parameter Table:**
   ```r
   printcp(simple_tree_oversample)
   ```
 **Variable Importance:**
   ```r
   importance_oversample = varImp(simple_tree_oversample, scale = FALSE)
   print(importance_oversample)
   ```
 **Confusion Matrix:**
    ```r
   predictions_tree_oversample = predict(simple_tree_oversample, train_data_oversample, type = "class")
   confusion_matrix_tree_oversample = table(predictions_tree_oversample, train_data_oversample$Churn)
   print(confusion_matrix_tree_oversample)
   ```

The root node splits at `Total.day.minutes < 247` while, regardiong the second level splits, the paths used to elaborate further separations are exactly the same of those used in the under sample data. The outcome results in a higher probability of churn  seen in nodes with more total day minutes and more customer service calls. It is used to handle imbalanced data by duplicating minority class samples.

Each diagram represents a decision tree used to classify the probability of customer churn based on various features. The differences mainly arise from the data balancing techniques (oversampling, undersampling, normal). These trees demonstrate how different data balancing techniques affect the decision tree's structure and the resulting classification of churn probabilities.

This detailed analysis of classification tree models trained with "Total Day Minutes," "International Plan," and "Customer Service Calls" demonstrates the significance of these variables in predicting customer churn. By comparing models trained on normal, undersampled, and oversampled datasets, the analysis evaluates the impact of data balancing techniques on model performance. The visualizations and evaluation metrics provide clear insights into how the classification tree models handle different data balancing approaches.


